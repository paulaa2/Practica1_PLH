{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocès: ##\n",
    "\n",
    "- Eliminar els digits del text\n",
    "- Convertir tot el text a minúscula\n",
    "- Substitueix els espais en blanc continus per un de sol\n",
    "- Concatena totes les frases amb un espai doble al mig \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from nltk.collocations import TrigramCollocationFinder, ngrams\n",
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\d+', '', text)  # Delete numbers\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Delete multiple spaces\n",
    "    text = re.sub(r'\\n', '  ', text)  # Doble space for new line  \n",
    "    return text\n",
    "\n",
    "def load_and_preprocess_data(data_path):\n",
    "    with open(data_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return preprocess_text(text)\n",
    "\n",
    "\n",
    "languages = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "path = 'C:/Users/Paess/Documents/Uni/Segon/PLH/langId'\n",
    "train = {}\n",
    "test = []\n",
    "\n",
    "for idiom in languages:\n",
    "    file_path = os.path.join(path, f'{idiom}_trn.txt')\n",
    "    text = load_and_preprocess_data(file_path)\n",
    "    train[idiom] = text\n",
    "\n",
    "for idiom in languages:\n",
    "    file_path = os.path.join(path, f'{idiom}_tst.txt')\n",
    "    texts = load_and_preprocess_data(file_path).split('  ')\n",
    "    test.extend([(text, idiom) for text in texts])\n",
    "    X_test, y_test = zip(*test)\n",
    "\n",
    "\n",
    "train_split = {}\n",
    "val_split = {}\n",
    "\n",
    "for idiom in languages:\n",
    "    text = train[idiom]\n",
    "    split_index = int(len(text) * 0.8)\n",
    "    train_split[idiom] = text[:split_index]\n",
    "    val_split[idiom] = text[split_index:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " .. wissenschaft welche rolle das licht im wissenschaftsjahr in jena spielt weltweit wird dem thema \n"
     ]
    }
   ],
   "source": [
    "print(train_split['deu'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigrams(text_list):\n",
    "    lletres = [char for char in text]\n",
    "    trigrams = [''.join(trigram) for trigram in ngrams(lletres, 3) if len(trigram) == 3]\n",
    "    return trigrams\n",
    "\n",
    "def frequent_trigrams(trigrams):\n",
    "    trigram_counts = Counter(trigrams)\n",
    "    frequent_trigrams_set = {trigram for trigram, count in trigram_counts.items() if count >= 5}\n",
    "    return [trigram for trigram in trigrams if trigram in frequent_trigrams_set]\n",
    "\n",
    "for idiom in train_split: \n",
    "    train_split[idiom] = frequent_trigrams(generate_trigrams(train_split[idiom]))\n",
    "    val_split[idiom] = frequent_trigrams(generate_trigrams(val_split[idiom]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_lang = {}\n",
    "for lang, trigrams in train_split.items():\n",
    "    NT = len(trigrams)\n",
    "    B = 30**3\n",
    "    info_lang[lang] = {'NT': NT, 'B': B}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LID = Ct(ej)+lambda/Nt+lambdaB, B= # trigrames diferents Nt= # trigrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LID(count_trigram, NT, B, lam=0.5):\n",
    "    return np.log((count_trigram + lam) / (NT + lam * B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenament_model(train, lam=0.5):\n",
    "    trigram_counts = {trigram: {lang: 0 for lang in languages} for lang in languages for trigram in train.get(lang, [])}\n",
    "    \n",
    "    for lang, lang_trigrams in train.items():\n",
    "        for trigram in lang_trigrams:\n",
    "            trigram_counts[trigram][lang] += 1\n",
    "    \n",
    "    trigram_LID = {}\n",
    "    for trigram, lang_counts in trigram_counts.items():\n",
    "        trigram_LID[trigram] = {lang: LID(count, info_lang[lang]['NT'], info_lang[lang]['B'], lam) for lang, count in lang_counts.items()}\n",
    "    \n",
    "    return trigram_LID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_language(text, trigram_LID, lam=0.5):\n",
    "    text_preprocessat = preprocess_text(text)  \n",
    "    trigrams = generate_trigrams([text_preprocessat]) \n",
    "    \n",
    "    LID_per_lang = {lang: 0 for lang in info_lang}  \n",
    "    \n",
    "    for trigram in trigrams:\n",
    "        if trigram in trigram_LID:\n",
    "            LID_per_lang_trigram = trigram_LID[trigram]  \n",
    "        else:\n",
    "            LID_per_lang_trigram = {lang: LID(0, info_lang[lang]['NT'], info_lang[lang]['B'], lam) for lang in info_lang}\n",
    "        for lang, LID_trigram in LID_per_lang_trigram.items():\n",
    "            LID_per_lang[lang] += LID_trigram \n",
    "    max_language = max(LID_per_lang, key=LID_per_lang.get)  \n",
    "    \n",
    "    return LID_per_lang, max_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_LID = entrenament_model(train_split, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'deu': np.float64(-29.03945032781779), 'eng': np.float64(-29.03945032781779), 'fra': np.float64(-29.03945032781779), 'ita': np.float64(-29.03945032781779), 'nld': np.float64(-29.03945032781779), 'spa': np.float64(-29.03945032781779)}, 'deu')\n"
     ]
    }
   ],
   "source": [
    "text = \"Hola\"\n",
    "\n",
    "print(predict_language(text, trigram_LID, 0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
