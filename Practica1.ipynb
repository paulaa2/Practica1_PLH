{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocès: ##\n",
    "\n",
    "- Eliminar els digits del text\n",
    "- Convertir tot el text a minúscula\n",
    "- Substitueix els espais en blanc continus per un de sol\n",
    "- Concatena totes les frases amb un espai doble al mig \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from nltk.collocations import TrigramCollocationFinder, ngrams\n",
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\d+', '', text) \n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\n', '  ', text)  \n",
    "    return text\n",
    "\n",
    "def load_and_preprocess_data(data_path):\n",
    "    with open(data_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return preprocess_text(text)\n",
    "\n",
    "\n",
    "languages = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "path = 'C:/Users/Paess/Documents/Uni/Segon/PLH/langId'\n",
    "train = {}\n",
    "test = []\n",
    "\n",
    "for idiom in languages:\n",
    "    file_path = os.path.join(path, f'{idiom}_trn.txt')\n",
    "    text = load_and_preprocess_data(file_path)\n",
    "    train[idiom] = text\n",
    "\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for idiom in languages:\n",
    "    file_path = os.path.join(path, f'{idiom}_tst.txt')\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines() \n",
    "    \n",
    "    for line in lines:\n",
    "        sentence = preprocess_text(line.strip()) \n",
    "        if sentence:  \n",
    "            X_test.append(sentence)\n",
    "            y_test.append(idiom)\n",
    "\n",
    "train_split = {}\n",
    "val_split = {}\n",
    "\n",
    "for idiom in languages:\n",
    "    text = train[idiom]\n",
    "    split_index = int(len(text) * 0.8)\n",
    "    train_split[idiom] = text[:split_index]\n",
    "    val_split[idiom] = text[split_index:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigrams(text):\n",
    "    \n",
    "    lletres = list(text)  # Convierte el texto en una lista de caracteres\n",
    "    trigrams = [''.join(trigram) for trigram in ngrams(lletres, 3) if len(trigram) == 3]\n",
    "    return trigrams\n",
    "\n",
    "def frequent_trigrams(trigrams):\n",
    "    trigram_counts = Counter(trigrams)\n",
    "    frequent_trigrams_set = {trigram for trigram, count in trigram_counts.items() if count >= 5}\n",
    "    return [trigram for trigram in trigrams if trigram in frequent_trigrams_set]\n",
    "\n",
    "\n",
    "\n",
    "for idiom in train_split: \n",
    "    train_split[idiom] = frequent_trigrams(generate_trigrams(train_split[idiom]))\n",
    "    val_split[idiom] = frequent_trigrams(generate_trigrams(val_split[idiom]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_lang = {}\n",
    "for lang, trigrams in train_split.items():\n",
    "    NT = len(trigrams)\n",
    "    B = 30**3\n",
    "    info_lang[lang] = {'NT': NT, 'B': B}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LID = Ct(ej)+lambda/Nt+lambdaB, B= # trigrames diferents Nt= # trigrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LID(count_trigram, NT, B, lam=0.5):\n",
    "    result= np.log((count_trigram + lam) / (NT + lam * B))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenament_model(train, lam=0.5):\n",
    "    trigram_counts = {trigram: {lang: 0 for lang in languages} for lang in languages for trigram in train.get(lang, [])}\n",
    "    \n",
    "    for lang, lang_trigrams in train.items():\n",
    "        for trigram in lang_trigrams:\n",
    "            trigram_counts[trigram][lang] += 1\n",
    "    \n",
    "    trigram_LID = {}\n",
    "    for trigram, lang_counts in trigram_counts.items():\n",
    "        trigram_LID[trigram] = {lang: LID(count, info_lang[lang]['NT'], info_lang[lang]['B'], lam) for lang, count in lang_counts.items()}\n",
    "    \n",
    "    return trigram_LID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(text, trigram_LID, lam=0.5):\n",
    "    text_preprocessat = preprocess_text(text)  \n",
    "    trigrams = generate_trigrams(text_preprocessat) \n",
    "    \n",
    "    LID_per_lang = {lang: 0 for lang in info_lang}  \n",
    "    \n",
    "    for trigram in trigrams:\n",
    "        if trigram in trigram_LID:\n",
    "            LID_per_lang_trigram = trigram_LID[trigram]  \n",
    "        else:\n",
    "            LID_per_lang_trigram = {lang: LID(0, info_lang[lang]['NT'], info_lang[lang]['B'], lam) for lang in info_lang}\n",
    "        for lang, LID_trigram in LID_per_lang_trigram.items():\n",
    "            LID_per_lang[lang] += LID_trigram \n",
    "\n",
    "    min_val = min(LID_per_lang.values())\n",
    "    max_val = max(LID_per_lang.values())\n",
    "    \n",
    "    if max_val == min_val: \n",
    "        probabilities = {lang: float(100 / len(LID_per_lang)) for lang in LID_per_lang}\n",
    "    else:\n",
    "        probabilities = {lang: float(((score - min_val) / (max_val - min_val)) * 100) for lang, score in LID_per_lang.items()}  \n",
    "\n",
    "    max_language = max(probabilities, key=probabilities.get)  \n",
    "\n",
    "    return probabilities, max_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_LID = entrenament_model(train_split, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'deu': 0.0, 'eng': 35.04509486508014, 'fra': 35.185960429637674, 'ita': 44.41237071387217, 'nld': 5.242111175603981, 'spa': 100.0}, 'spa')\n"
     ]
    }
   ],
   "source": [
    "text = \"Hola, com estás?\"\n",
    "\n",
    "print(predict(text, trigram_LID, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the results of the LID system by comparing the predicted languages with the actual languages\n",
    "\n",
    "def test(X_test, y_test, trigram_LID, lam=0.5):\n",
    "    y_pred = []\n",
    "    for sentence, actual_lang in zip(X_test, y_test):\n",
    "        _, lang = predict(sentence, trigram_LID, lam)\n",
    "        y_pred.append(lang)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=None)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    return accuracy, precision, f1, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, f1, conf_matrix = test(X_test, y_test, trigram_LID, 0.5)\n",
    "\n",
    "# Mostrar métricas de evaluación\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "\n",
    "# Define the class labels\n",
    "classes = np.unique(y_test)\n",
    "\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 12}, cmap=\"Blues\", fmt=\".2f\", xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
